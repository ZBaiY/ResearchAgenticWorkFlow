#!/usr/bin/env python3
import argparse
import hmac
import json
import os
import re
import secrets
import subprocess
import sys
import time
import traceback
from datetime import datetime, timezone
from json import JSONDecodeError
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


def now_utc() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def utc_compact() -> str:
    return datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")


def repo_root() -> Path:
    return Path(__file__).resolve().parent.parent


def agents_root(root: Path) -> Path:
    return root / "AGENTS"


def skills_dir(root: Path) -> Path:
    return agents_root(root) / "skills"


def tasks_dir(root: Path) -> Path:
    return agents_root(root) / "tasks"


def runtime_dir(root: Path) -> Path:
    return agents_root(root) / "runtime"


def index_path(root: Path) -> Path:
    return runtime_dir(root) / "skills_index.json"


def run_cmd(cmd: List[str], cwd: Path) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, cwd=str(cwd), text=True, capture_output=True)


def env_truthy(name: str, default: bool = False) -> bool:
    raw = os.environ.get(name)
    if raw is None:
        return default
    return raw.strip().lower() in {"1", "true", "yes", "y", "on"}


class NonInteractivePromptError(RuntimeError):
    pass


class SkillSubprocessError(RuntimeError):
    def __init__(self, skill: str, returncode: int, stdout: str, stderr: str):
        super().__init__(f"Skill '{skill}' failed with exit code {returncode}")
        self.skill = skill
        self.returncode = returncode
        self.stdout = stdout
        self.stderr = stderr


TOOL_TRACE_PATTERNS = [
    re.compile(r"functions\.exec_command"),
    re.compile(r"to=functions\.exec_command"),
    re.compile(r"\brecipient_name\b"),
    re.compile(r"\btool_uses\b"),
]
NON_BUSINESS_BLOCKLIST = ["彩票", "博彩", "娱乐平台", "网站"]


def write_trace_debug_line(root: Path, task_id: str, line: str, reason: str) -> None:
    try:
        review_dir = tasks_dir(root) / task_id / "review"
        review_dir.mkdir(parents=True, exist_ok=True)
        out = review_dir / "trace_debug.log"
        with out.open("a", encoding="utf-8") as handle:
            handle.write(f"{now_utc()} [{reason}] {line}\n")
    except Exception:
        return


def sanitize_user_lines(root: Path, task_id: str, raw: str) -> str:
    if not raw:
        return ""
    kept: List[str] = []
    for line in raw.splitlines():
        stripped = line.strip()
        drop_reason = ""
        if any(p.search(line) for p in TOOL_TRACE_PATTERNS):
            drop_reason = "tool_trace"
        elif any(w in line for w in NON_BUSINESS_BLOCKLIST):
            drop_reason = "non_business"
        elif any(ord(ch) > 127 for ch in line):
            drop_reason = "non_ascii"
        elif stripped.startswith("{") or stripped.startswith("}"):
            if any(key in line for key in ("tool_uses", "recipient_name", "functions.exec_command")):
                drop_reason = "tool_json"
        if drop_reason:
            write_trace_debug_line(root, task_id, line, drop_reason)
            continue
        kept.append(line)
    return "\n".join(kept).strip()


COMPUTE_REQUEST_REQUIRED_FIELDS = [
    "goal",
    "inputs",
    "expected_outputs",
    "constraints",
    "preferred_formats",
]

COMPUTE_REQUEST_STEPS = ["goal", "inputs", "expected_outputs", "constraints", "preferred_formats", "done"]
MULTISTEP_POLICY_STEPS = [
    "policy_customize",
    "policy_max_steps",
    "policy_time_limit_sec_per_step",
    "policy_max_leaf_count",
    "policy_overrides",
]
MULTISTEP_POLICY_FIELDS = [
    "policy_customize",
    "policy_max_steps",
    "policy_time_limit_sec_per_step",
    "policy_max_leaf_count",
    "policy_overrides",
]
MULTISTEP_REQUEST_FIELDS = COMPUTE_REQUEST_REQUIRED_FIELDS + MULTISTEP_POLICY_FIELDS
SUPPORTED_REQUEST_SKILLS = {"compute_numerical", "compute_algebraic", "compute_algebraic_multistep"}
MULTISTEP_POLICY_DEFAULTS: Dict[str, Any] = {
    "max_steps": 8,
    "time_limit_sec_per_step": 10,
    "max_leaf_count": 50000,
    "assumptions": "",
    "check_level": "equivalence",
    "allowlist_ops": [
        "Simplify",
        "FullSimplify",
        "Assuming",
        "Refine",
        "Together",
        "Factor",
        "Apart",
        "FunctionExpand",
        "TrigReduce",
        "Series",
        "Normal",
        "Solve",
        "Reduce",
        "Integrate",
        "D",
    ],
}

COMPUTE_STEP_PROMPTS: Dict[str, str] = {
    "goal": (
        "What is the goal of this computation? (Describe in natural language; you can be detailed.)\n"
        'Example: "Symbolically simplify my expression and derive the closed-form for the integral under assumptions a>0, b>0."'
    ),
    "inputs": (
        "What are the inputs? Provide variables, expressions, known constants, and any assumptions.\n"
        'Example:\n'
        '- variables: {"a": "positive real", "b": "positive real"}\n'
        '- expression: "Integrate[Exp[-a x^2] Cos[b x], {x, 0, Infinity}]"\n'
        '- assumptions: "a>0 && b∈Reals"'
    ),
    "expected_outputs": (
        "What outputs do you expect? Be specific about what should be returned.\n"
        'Example:\n'
        '- "closed_form_expression"\n'
        '- "simplified_form"\n'
        '- "verification (differentiate result)"\n'
        '- "optional: numeric check at a=1, b=2"'
    ),
    "constraints": (
        "Any constraints? (runtime limits, accuracy, no-network, allowed tools, etc.) List them.\n"
        'Example:\n'
        '- "No internet access"\n'
        '- "Keep runtime < 10s"\n'
        '- "Do not use external Mathematica packages"'
    ),
    "preferred_formats": (
        "Preferred output formats? (e.g., plain text, LaTeX, JSON, CSV, PDF figures) List them.\n"
        'Example:\n'
        '- "LaTeX for final formulas"\n'
        '- "Plain text summary in report"\n'
        '- "PNG plots if any"'
    ),
}

MULTISTEP_STEP_PROMPTS: Dict[str, str] = {
    "goal": "What is the goal of this symbolic multistep computation? Describe in natural language.",
    "inputs": "What are the inputs? Provide variables, expressions, known constants, and assumptions.",
    "expected_outputs": "What do you expect as outputs? Be specific about symbolic results, formats, or types.",
    "constraints": "Any constraints to apply? (runtime limits, accuracy, tool restrictions)",
    "preferred_formats": "Preferred output formats? (Plain text, LaTeX, JSON, PDF figures, etc.)",
    "policy_customize": "Do you want to customize execution policy (yes/no)? (default: no)",
    "policy_max_steps": "Max number of plan steps? (default 8)",
    "policy_time_limit_sec_per_step": "Time limit per step in seconds? (default 10)",
    "policy_max_leaf_count": "Max expression complexity (LeafCount cap)? (default 50000)",
    "policy_overrides": "Any other policy overrides? If yes, paste a JSON object with overrides. Else reply no.",
}

SCHEMA_MIN_EXAMPLES: Dict[str, str] = {
    "goal": "goal: simplify symbolic expression for integral identity",
    "inputs": "variables: x, a; expression: exp(a*x); assumptions: a real",
    "expected_outputs": "symbolic_result: simplified form; check: equivalence statement",
    "constraints": "assumptions: a>0, x in Reals; limits: time<10s; tools: local symbolic only; network: none",
    "preferred_formats": "output: plain text; formulas: latex; table: csv",
    "policy_customize": "choice: yes or no; default: no",
    "policy_max_steps": "max_steps: 6",
    "policy_time_limit_sec_per_step": "time_limit_sec_per_step: 8",
    "policy_max_leaf_count": "max_leaf_count: 40000",
    "policy_overrides": "assumptions: x>0; check_level: equivalence",
}

MULTISTEP_SCHEMA_MIN_EXAMPLES: Dict[str, str] = {
    "constraints": "assumptions: a>0, x in Reals; limits: time<10s; tools: local symbolic only; network: none",
}


def strip_quotes(s: str) -> str:
    s = s.strip()
    if len(s) >= 2 and ((s[0] == '"' and s[-1] == '"') or (s[0] == "'" and s[-1] == "'")):
        return s[1:-1]
    return s


def parse_skill_yaml(path: Path) -> Tuple[Dict[str, Any], List[str]]:
    warnings: List[str] = []
    data: Dict[str, Any] = {
        "name": "",
        "title": "",
        "description": "",
        "run": "scripts/run.sh",
        "prompt": "prompts/prompt.md",
        "schema": "schemas/schema.json",
        "keywords": [],
        "outputs": [],
        "requires_network": False,
        "preferred_runner": [],
        "risk": "medium",
        "confirmations": [],
        "clarification_policy": "auto",
    }
    if not path.exists():
        warnings.append("missing skill.yaml")
        return data, warnings

    lines = path.read_text(encoding="utf-8").splitlines()
    i = 0
    while i < len(lines):
        raw = lines[i]
        i += 1
        if not raw.strip() or raw.lstrip().startswith("#"):
            continue
        m = re.match(r"^([A-Za-z_][A-Za-z0-9_]*):\s*(.*)$", raw)
        if not m:
            continue
        key, val = m.group(1), m.group(2).strip()
        if key in {"name", "title", "description", "risk", "clarification_policy", "run", "prompt", "schema"}:
            data[key] = strip_quotes(val)
        elif key == "requires_network":
            data[key] = val.lower() == "true"
        elif key in {"keywords", "preferred_runner", "confirmations"}:
            items: List[str] = []
            while i < len(lines):
                l = lines[i]
                if re.match(r"^\s{2,}-\s+", l):
                    item = re.sub(r"^\s{2,}-\s+", "", l).strip()
                    items.append(strip_quotes(item))
                    i += 1
                else:
                    break
            data[key] = items
        elif key == "outputs":
            items: List[Dict[str, str]] = []
            while i < len(lines):
                l = lines[i]
                if re.match(r"^\s{2,}-\s+", l):
                    item = re.sub(r"^\s{2,}-\s+", "", l).strip()
                    if ":" in item:
                        k, v = item.split(":", 1)
                        items.append({k.strip(): strip_quotes(v.strip())})
                    i += 1
                else:
                    break
            data["outputs"] = items

    if not data.get("name"):
        warnings.append("skill.yaml missing name")
    if not data.get("description"):
        warnings.append("skill.yaml missing description")
    if not isinstance(data.get("keywords"), list):
        warnings.append("skill.yaml keywords malformed")
        data["keywords"] = []
    if data.get("run") != "scripts/run.sh":
        warnings.append("skill.yaml run must be scripts/run.sh")
    return data, warnings


def build_index(root: Path) -> Dict[str, Any]:
    sdir = skills_dir(root)
    idx: Dict[str, Any] = {
        "generated_at_utc": now_utc(),
        "repo_root": str(root),
        "skills": [],
        "warnings": [],
    }
    for p in sorted(sdir.iterdir()):
        if not p.is_dir():
            continue
        name = p.name
        sy = p / "skill.yaml"
        meta, warns = parse_skill_yaml(sy)
        prompt_rel = str(meta.get("prompt", "prompts/prompt.md"))
        run_rel = str(meta.get("run", "scripts/run.sh"))
        schema_rel = str(meta.get("schema", "schemas/schema.json"))
        prompt = p / prompt_rel
        runsh = p / run_rel
        schema = p / schema_rel
        degraded = not sy.exists() or len(warns) > 0
        if degraded:
            desc = ""
            if prompt.exists():
                for line in prompt.read_text(encoding="utf-8").splitlines():
                    t = line.strip()
                    if t and not t.startswith("#"):
                        desc = t
                        break
            if not meta.get("name"):
                meta["name"] = name
            if not meta.get("title"):
                meta["title"] = name
            if not meta.get("description"):
                meta["description"] = desc or "No description available"

        rec = {
            "name": name,
            "path": str(p.relative_to(root)),
            "title": meta.get("title", name),
            "description": meta.get("description", ""),
            "run": run_rel,
            "prompt": prompt_rel,
            "schema": schema_rel,
            "keywords": meta.get("keywords", []),
            "outputs": meta.get("outputs", []),
            "requires_network": bool(meta.get("requires_network", False)),
            "preferred_runner": meta.get("preferred_runner", []),
            "risk": meta.get("risk", "medium"),
            "confirmations": meta.get("confirmations", []),
            "clarification_policy": meta.get("clarification_policy", "auto"),
            "has_run_sh": runsh.exists(),
            "has_prompt_md": prompt.exists(),
            "has_schema": schema.exists(),
            "degraded": degraded,
            "warnings": warns,
        }
        idx["skills"].append(rec)
        for w in warns:
            idx["warnings"].append(f"{name}: {w}")

    runtime_dir(root).mkdir(parents=True, exist_ok=True)
    index_path(root).write_text(json.dumps(idx, indent=2), encoding="utf-8")
    return idx


def ensure_index(root: Path) -> Dict[str, Any]:
    ip = index_path(root)
    if not ip.exists():
        return build_index(root)
    return json.loads(ip.read_text(encoding="utf-8"))


def tokenize(text: str) -> List[str]:
    return re.findall(r"[a-z0-9_+-]+", text.lower())


def score_skill(skill: Dict[str, Any], query: str) -> int:
    qtokens = tokenize(query)
    fields = " ".join(
        [
            skill.get("name", ""),
            skill.get("title", ""),
            skill.get("description", ""),
            " ".join(skill.get("keywords", []) or []),
        ]
    ).lower()
    score = 0
    for t in qtokens:
        if t in fields:
            score += 1
    if skill.get("name", "") in query.lower():
        score += 3
    return score


def cmd_index(root: Path) -> int:
    idx = build_index(root)
    print(f"INDEX={index_path(root)} SKILLS={len(idx.get('skills', []))} WARNINGS={len(idx.get('warnings', []))}")
    for w in idx.get("warnings", []):
        print(f"WARN={w}")
    return 0


def fmt_outputs(outputs: List[Dict[str, str]]) -> str:
    if not outputs:
        return "NONE"
    parts = []
    for item in outputs:
        for k, v in item.items():
            parts.append(f"{k}:{v}")
    return " | ".join(parts)


def cmd_suggest(root: Path, text: str) -> int:
    idx = ensure_index(root)
    skills = idx.get("skills", [])
    ranked = sorted(skills, key=lambda s: (-score_skill(s, text), s.get("name", "")))
    top = ranked[:5]

    for s in top:
        print(
            "CARD="
            f"SKILL={s.get('name')} "
            f"DESC={s.get('description','').replace(' ', '_')} "
            f"RISK={s.get('risk','medium')} "
            f"NETWORK={str(bool(s.get('requires_network', False))).lower()} "
            f"OUTPUTS={fmt_outputs(s.get('outputs', [])).replace(' ', '_')}"
        )

    if not top:
        print("RECOMMENDED=NONE")
        return 0

    s0 = score_skill(top[0], text)
    ties = [s for s in ranked if score_skill(s, text) == s0 and s0 > 0]
    if len(ties) == 1:
        print(f"RECOMMENDED={top[0].get('name')}")
    else:
        print("RECOMMENDED=NONE")
    return 0


def git_head(root: Path) -> str:
    cp = run_cmd(["git", "rev-parse", "HEAD"], root)
    if cp.returncode != 0:
        return ""
    return cp.stdout.strip()


def write_request(task_dir: Path, args: argparse.Namespace) -> str:
    req_path = task_dir / "request.md"
    if args.request == "-":
        content = sys.stdin.read()
        req_path.write_text(content, encoding="utf-8")
        return "stdin"
    if args.request and args.request != "?":
        src = Path(args.request).expanduser()
        if not src.is_absolute():
            src = (repo_root() / src).resolve()
        if src.exists():
            content = src.read_text(encoding="utf-8")
        else:
            src.parent.mkdir(parents=True, exist_ok=True)
            content = (
                "# Request\n\n"
                "Goal:\n"
                "TBD\n\n"
                "Background:\n"
                "TBD\n\n"
                "Constraints:\n"
                "- TBD\n\n"
                "Deliverables:\n"
                "- TBD\n"
            )
            src.write_text(content, encoding="utf-8")
        req_path.write_text(content, encoding="utf-8")
        return f"request:{src}"
    if args.request_file:
        src = Path(args.request_file).expanduser().resolve()
        content = src.read_text(encoding="utf-8")
        req_path.write_text(content, encoding="utf-8")
        return f"file:{src}"
    if args.edit:
        if not req_path.exists() or not req_path.read_text(encoding="utf-8").strip():
            req_path.write_text(
                "# Request\n\nGoal:\nTBD\n\nConstraints:\n- TBD\n\nInputs:\n- TBD\n",
                encoding="utf-8",
            )
        editor = os.environ.get("EDITOR", "vim")
        subprocess.run([editor, str(req_path)], check=False)
        return f"editor:{editor}"

    req_path.write_text(
        "# Request\n\nGoal:\nTBD\n\nBackground:\nTBD\n\nConstraints:\n- TBD\n\nDeliverables:\n- TBD\n",
        encoding="utf-8",
    )
    editor = os.environ.get("EDITOR", "vim")
    subprocess.run([editor, str(req_path)], check=False)
    return f"template+editor:{editor}"


def validate_task_name(name: str) -> bool:
    return bool(re.fullmatch(r"[A-Za-z0-9_]+", name))


def default_task_name(skill: str) -> str:
    return f"{skill}_{utc_compact()}"


def compute_request_paths(root: Path, task_id: str) -> Tuple[Path, Path]:
    tdir = tasks_dir(root) / task_id
    return tdir / "request.json", tdir / "request_progress.json"


def review_token_path(root: Path, task_id: str) -> Path:
    return tasks_dir(root) / task_id / "work" / "review_token.txt"


def atomic_write_json(path: Path, payload: Dict[str, Any]) -> None:
    tmp = path.with_suffix(path.suffix + ".tmp")
    tmp.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    tmp.replace(path)


def load_request_progress(root: Path, task_id: str) -> Dict[str, Any]:
    _, progress_json = compute_request_paths(root, task_id)
    if not progress_json.exists():
        return {}
    try:
        payload = json.loads(progress_json.read_text(encoding="utf-8"))
    except Exception:
        return {}
    return payload if isinstance(payload, dict) else {}


def request_fields_for_skill(skill: str) -> List[str]:
    if skill == "compute_algebraic_multistep":
        return list(MULTISTEP_REQUEST_FIELDS)
    return list(COMPUTE_REQUEST_REQUIRED_FIELDS)


def request_prompts_for_skill(skill: str) -> Dict[str, str]:
    if skill == "compute_algebraic_multistep":
        return MULTISTEP_STEP_PROMPTS
    return COMPUTE_STEP_PROMPTS


def schema_question_line(skill: str, step: str) -> str:
    prompts = request_prompts_for_skill(skill)
    raw = prompts.get(step, "Please provide the missing request field.")
    first = raw.splitlines()[0].strip()
    return first or "Please provide the missing request field."


def schema_example_line(step: str, skill: str = "") -> str:
    if skill == "compute_algebraic_multistep" and step in MULTISTEP_SCHEMA_MIN_EXAMPLES:
        return MULTISTEP_SCHEMA_MIN_EXAMPLES[step]
    return SCHEMA_MIN_EXAMPLES.get(step, "field: value")


def init_compute_request_files(root: Path, task_id: str, skill: str) -> None:
    req_json, progress_json = compute_request_paths(root, task_id)
    payload: Dict[str, Any] = {
        "goal": "",
        "inputs": {},
        "expected_outputs": {},
        "constraints": [],
        "preferred_formats": [],
    }
    if skill == "compute_algebraic_multistep":
        payload["policy"] = dict(MULTISTEP_POLICY_DEFAULTS)
    if not req_json.exists():
        req_json.write_text(
            json.dumps(payload, indent=2),
            encoding="utf-8",
        )
    atomic_write_json(
        progress_json,
        {
            "current_step": "goal",
            "updated_at": now_utc(),
            "review_ready_for_execute": False,
        },
    )


def load_compute_request(root: Path, task_id: str) -> Dict[str, Any]:
    req_json, _ = compute_request_paths(root, task_id)
    if not req_json.exists():
        payload: Dict[str, Any] = {
            "goal": "",
            "inputs": {},
            "expected_outputs": {},
            "constraints": [],
            "preferred_formats": [],
        }
        return payload
    return json.loads(req_json.read_text(encoding="utf-8"))


def normalize_object_value(raw: str) -> Dict[str, Any]:
    txt = raw.strip()
    if not txt:
        return {}
    try:
        obj = json.loads(txt)
        if isinstance(obj, dict):
            return obj
    except Exception:
        pass
    out: Dict[str, Any] = {}
    for line in txt.splitlines():
        s = line.strip()
        if not s:
            continue
        if s.startswith("- "):
            s = s[2:].strip()
        if ":" in s:
            k, v = s.split(":", 1)
            out[k.strip()] = v.strip()
    return out


def normalize_array_value(raw: str) -> List[str]:
    txt = raw.strip()
    if not txt:
        return []
    try:
        arr = json.loads(txt)
        if isinstance(arr, list):
            return [str(x).strip() for x in arr if str(x).strip()]
    except Exception:
        pass
    lines = [x.strip() for x in txt.splitlines() if x.strip()]
    out: List[str] = []
    for line in lines:
        s = line
        if s.startswith("- "):
            s = s[2:].strip()
        if s:
            out.append(s)
    if out:
        return out
    return [x.strip() for x in txt.split(",") if x.strip()]


def compute_next_step(payload: Dict[str, Any]) -> str:
    for k in COMPUTE_REQUEST_REQUIRED_FIELDS:
        v = payload.get(k)
        if k == "goal" and not str(v or "").strip():
            return k
        if k in {"inputs", "expected_outputs"} and not isinstance(v, dict):
            return k
        if k in {"inputs", "expected_outputs"} and isinstance(v, dict) and len(v) == 0:
            return k
        if k in {"constraints", "preferred_formats"} and (not isinstance(v, list) or len(v) == 0):
            return k
    return "done"


def is_compute_skill(skill: str) -> bool:
    return str(skill or "").startswith("compute_")


def merge_multistep_policy_defaults(payload: Dict[str, Any]) -> Dict[str, Any]:
    policy = payload.get("policy", {})
    if not isinstance(policy, dict):
        policy = {}
    for key, value in MULTISTEP_POLICY_DEFAULTS.items():
        if key not in policy:
            policy[key] = value
    payload["policy"] = policy
    return payload


def write_request_progress(
    root: Path,
    task_id: str,
    current_step: str,
    review_ready_for_execute: Optional[bool] = None,
    review_token: Optional[str] = None,
    review_token_issued_at: Optional[str] = None,
) -> None:
    _, progress_json = compute_request_paths(root, task_id)
    progress = load_request_progress(root, task_id)
    progress["current_step"] = current_step
    progress["updated_at"] = now_utc()
    if review_ready_for_execute is None:
        if "review_ready_for_execute" not in progress:
            progress["review_ready_for_execute"] = False
    else:
        progress["review_ready_for_execute"] = bool(review_ready_for_execute)
    if review_token is not None:
        progress["review_token"] = review_token
    if review_token_issued_at is not None:
        progress["review_token_issued_at"] = review_token_issued_at
    atomic_write_json(progress_json, progress)


def review_ready_for_execute(root: Path, task_id: str) -> bool:
    progress = load_request_progress(root, task_id)
    return bool(progress.get("review_ready_for_execute", False))


def current_review_token(root: Path, task_id: str) -> str:
    progress = load_request_progress(root, task_id)
    token = str(progress.get("review_token", "")).strip()
    if token:
        return token
    token_file = review_token_path(root, task_id)
    if token_file.exists():
        return token_file.read_text(encoding="utf-8").strip()
    return ""


def issue_review_token(root: Path, task_id: str, current_step: str = "done") -> None:
    token = secrets.token_hex(4)
    token_file = review_token_path(root, task_id)
    token_file.parent.mkdir(parents=True, exist_ok=True)
    token_file.write_text(token + "\n", encoding="utf-8")
    issued_at = now_utc()
    write_request_progress(
        root,
        task_id,
        current_step,
        review_ready_for_execute=False,
        review_token=token,
        review_token_issued_at=issued_at,
    )


def request_preflight_status(root: Path, task_id: str, skill: str) -> Dict[str, Any]:
    req_json, _ = compute_request_paths(root, task_id)
    payload: Dict[str, Any] = {}
    if req_json.exists():
        try:
            payload = json.loads(req_json.read_text(encoding="utf-8"))
        except Exception:
            payload = {}
    if not isinstance(payload, dict):
        payload = {}

    if skill == "compute_algebraic_multistep":
        payload = merge_multistep_policy_defaults(payload)
        req_json.write_text(json.dumps(payload, indent=2), encoding="utf-8")

    next_step = compute_next_step(payload)

    request_complete = next_step == "done"
    write_request_progress(root, task_id, next_step)
    return {
        "request_complete": request_complete,
        "request_step": next_step,
    }


def write_need_input_md(root: Path, task_id: str, skill: str, request_step: str) -> str:
    review_dir = tasks_dir(root) / task_id / "review"
    review_dir.mkdir(parents=True, exist_ok=True)
    out = review_dir / "need_input.md"
    prompts = request_prompts_for_skill(skill)
    prompt_text = prompts.get(request_step, "Please provide the missing request field.")
    out.write_text(
        (
            "# Input Needed\n\n"
            f"- task_id: {task_id}\n"
            f"- skill: {skill}\n"
            "- request_complete: false\n"
            f"- request_step: {request_step}\n\n"
            "## Next question (English)\n"
            f"{prompt_text}\n"
        ),
        encoding="utf-8",
    )
    return str(out.relative_to(root))


def next_step_for_multistep(payload: Dict[str, Any], updated_field: str, raw_value: str) -> str:
    for key in COMPUTE_REQUEST_REQUIRED_FIELDS:
        val = payload.get(key)
        if key == "goal" and not str(val or "").strip():
            return key
        if key in {"inputs", "expected_outputs"} and (not isinstance(val, dict) or len(val) == 0):
            return key
        if key in {"constraints", "preferred_formats"} and (not isinstance(val, list) or len(val) == 0):
            return key
    answer = raw_value.strip().lower()
    if updated_field in COMPUTE_REQUEST_REQUIRED_FIELDS:
        return "policy_customize"
    if updated_field == "policy_customize":
        return "policy_max_steps" if answer in {"y", "yes", "true", "1"} else "policy_overrides"
    if updated_field == "policy_max_steps":
        return "policy_time_limit_sec_per_step"
    if updated_field == "policy_time_limit_sec_per_step":
        return "policy_max_leaf_count"
    if updated_field == "policy_max_leaf_count":
        return "policy_overrides"
    if updated_field == "policy_overrides":
        return "done"
    return "policy_customize"


def write_compute_request_state(
    root: Path,
    task_id: str,
    payload: Dict[str, Any],
    *,
    skill: str,
    updated_field: str,
    raw_value: str,
) -> str:
    req_json, _ = compute_request_paths(root, task_id)
    req_json.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    if skill == "compute_algebraic_multistep":
        next_step = next_step_for_multistep(payload, updated_field=updated_field, raw_value=raw_value)
    else:
        next_step = compute_next_step(payload)
    write_request_progress(root, task_id, next_step)
    return next_step


def cmd_request_set(root: Path, args: argparse.Namespace) -> int:
    task_id = args.task
    field = str(args.field or "").strip()
    meta_path = tasks_dir(root) / task_id / "meta.json"
    if not meta_path.exists():
        print(f"ERROR=Task not found: {task_id}", file=sys.stderr)
        return 2
    meta = json.loads(meta_path.read_text(encoding="utf-8"))
    skill = str(meta.get("skill", "")).strip()
    if skill not in SUPPORTED_REQUEST_SKILLS:
        print(f"ERROR=request-set is only supported for compute skills. skill={skill}", file=sys.stderr)
        return 2
    allowed_fields = set(request_fields_for_skill(skill))
    if field not in allowed_fields:
        print(f"ERROR=Invalid field: {field}", file=sys.stderr)
        return 2
    payload = load_compute_request(root, task_id)
    if skill == "compute_algebraic_multistep" and not isinstance(payload.get("policy"), dict):
        payload["policy"] = dict(MULTISTEP_POLICY_DEFAULTS)

    _, progress_json = compute_request_paths(root, task_id)
    current_step = ""
    if progress_json.exists():
        try:
            progress_obj = json.loads(progress_json.read_text(encoding="utf-8"))
            current_step = str(progress_obj.get("current_step", "")).strip()
        except Exception:
            current_step = ""
    if not current_step:
        current_step = compute_next_step(payload)
    if current_step == "done":
        print("ERROR=Request is already complete.", file=sys.stderr)
        return 2
    if field != current_step:
        print(f"ERROR=Expected field '{current_step}' next, got '{field}'.", file=sys.stderr)
        return 2
    if bool(args.value) == bool(args.file):
        print("ERROR=Provide exactly one of --value or --file.", file=sys.stderr)
        return 2
    raw = ""
    if args.value:
        raw = str(args.value)
    if args.file:
        src = Path(args.file).expanduser()
        if not src.is_absolute():
            src = (root / src).resolve()
        if not src.exists():
            print(f"ERROR=Value file not found: {src}", file=sys.stderr)
            return 2
        raw = src.read_text(encoding="utf-8")

    if field == "goal":
        payload[field] = raw.strip()
    elif field in {"inputs", "expected_outputs"}:
        payload[field] = normalize_object_value(raw)
    elif field == "policy_customize":
        answer = raw.strip().lower()
        if answer in {"y", "yes", "true", "1"}:
            payload["policy"] = dict(MULTISTEP_POLICY_DEFAULTS)
        else:
            payload["policy"] = dict(MULTISTEP_POLICY_DEFAULTS)
    elif field == "policy_max_steps":
        policy = dict(payload.get("policy") or MULTISTEP_POLICY_DEFAULTS)
        try:
            policy["max_steps"] = int(raw.strip() or str(MULTISTEP_POLICY_DEFAULTS["max_steps"]))
        except ValueError:
            policy["max_steps"] = int(MULTISTEP_POLICY_DEFAULTS["max_steps"])
        payload["policy"] = policy
    elif field == "policy_time_limit_sec_per_step":
        policy = dict(payload.get("policy") or MULTISTEP_POLICY_DEFAULTS)
        try:
            policy["time_limit_sec_per_step"] = int(
                raw.strip() or str(MULTISTEP_POLICY_DEFAULTS["time_limit_sec_per_step"])
            )
        except ValueError:
            policy["time_limit_sec_per_step"] = int(MULTISTEP_POLICY_DEFAULTS["time_limit_sec_per_step"])
        payload["policy"] = policy
    elif field == "policy_max_leaf_count":
        policy = dict(payload.get("policy") or MULTISTEP_POLICY_DEFAULTS)
        try:
            policy["max_leaf_count"] = int(raw.strip() or str(MULTISTEP_POLICY_DEFAULTS["max_leaf_count"]))
        except ValueError:
            policy["max_leaf_count"] = int(MULTISTEP_POLICY_DEFAULTS["max_leaf_count"])
        payload["policy"] = policy
    elif field == "policy_overrides":
        policy = dict(payload.get("policy") or MULTISTEP_POLICY_DEFAULTS)
        txt = raw.strip().lower()
        if txt not in {"", "no", "n"}:
            try:
                obj = json.loads(raw)
            except Exception:
                obj = {}
            if isinstance(obj, dict):
                for key in MULTISTEP_POLICY_DEFAULTS.keys():
                    if key in obj:
                        policy[key] = obj[key]
        payload["policy"] = policy
    else:
        payload[field] = normalize_array_value(raw)
    next_step = write_compute_request_state(
        root,
        task_id,
        payload,
        skill=skill,
        updated_field=field,
        raw_value=raw,
    )

    if skill == "compute_algebraic_multistep":
        req_md = tasks_dir(root) / task_id / "request.md"
        req_md.write_text(
            "# Request (mirror)\n\n```json\n"
            + json.dumps(payload, indent=2)
            + "\n```\n",
            encoding="utf-8",
        )

    print(f"REQUEST_FIELD_UPDATED={field}")
    print(f"REQUEST_STEP={next_step}")
    print(f"REQUEST_COMPLETE={'true' if next_step == 'done' else 'false'}")
    if next_step == "done":
        print("STOP_REASON=request_complete_waiting_user_run")
        print("Say continue and we will start to plan.")
    else:
        print("STOP_REASON=need_user_input")
        print(schema_question_line(skill, next_step))
        print(f"MIN_EXAMPLE: {schema_example_line(next_step, skill)}")
    return 0


def reserve_task_id(root: Path, skill: str) -> str:
    # Ensure uniqueness while preserving the <skill>_<timestamp> format.
    while True:
        candidate = default_task_name(skill)
        if not (tasks_dir(root) / candidate).exists():
            return candidate
        time.sleep(1)


def init_task_dir(root: Path, task_id: str) -> Path:
    tdir = tasks_dir(root) / task_id
    tdir.mkdir(parents=True, exist_ok=False)
    (tdir / "work").mkdir(parents=True, exist_ok=True)
    (tdir / "outputs" / "fig").mkdir(parents=True, exist_ok=True)
    (tdir / "outputs" / "tables").mkdir(parents=True, exist_ok=True)
    (tdir / "logs").mkdir(parents=True, exist_ok=True)
    (tdir / "review").mkdir(parents=True, exist_ok=True)
    (tdir / "deliverable").mkdir(parents=True, exist_ok=True)
    (tdir / "plan.md").write_text("# plan.md\n# Agent plan (to be filled by agent)\n", encoding="utf-8")
    return tdir


def cmd_start(root: Path, args: argparse.Namespace) -> int:
    if args.task_name:
        if not validate_task_name(args.task_name):
            print("ERROR=Invalid --task-name. Use only letters, digits, and underscores.", file=sys.stderr)
            return 2
        task_id = args.task_name
        if (tasks_dir(root) / task_id).exists():
            print(f"ERROR=Task already exists: {task_id}", file=sys.stderr)
            return 2
    else:
        task_id = reserve_task_id(root, args.skill)

    tdir = init_task_dir(root, task_id)

    source = write_request(tdir, args)

    meta = {
        "task_id": task_id,
        "skill": args.skill,
        "created_at_utc": now_utc(),
        "request_source": source,
        "repo_root": str(root),
        "git_head": git_head(root),
    }
    (tdir / "meta.json").write_text(json.dumps(meta, indent=2), encoding="utf-8")

    print(f"TASK={task_id} REQUEST=AGENTS/tasks/{task_id}/request.md")
    if args.skill in SUPPORTED_REQUEST_SKILLS:
        init_compute_request_files(root, task_id, skill=args.skill)
        if args.skill == "compute_algebraic_multistep":
            req_md = tasks_dir(root) / task_id / "request.md"
            req_md.write_text(
                "# Request (mirror)\n\n```json\n"
                + json.dumps(load_compute_request(root, task_id), indent=2)
                + "\n```\n",
                encoding="utf-8",
            )
        print(f"REQUEST_JSON=AGENTS/tasks/{task_id}/request.json")
        print(f"REQUEST_PROGRESS=AGENTS/tasks/{task_id}/request_progress.json")
        print("REQUEST_STEP=goal")
        print("REQUEST_COMPLETE=false")
        print("STOP_REASON=need_user_input")
        print(schema_question_line(args.skill, "goal"))
        print(f"MIN_EXAMPLE: {schema_example_line('goal', args.skill)}")
    return 0


def load_skill_from_index(idx: Dict[str, Any], skill: str) -> Dict[str, Any]:
    for s in idx.get("skills", []):
        if s.get("name") == skill:
            return s
    return {}


def infer_skill(root: Path, task_id: str) -> str:
    meta = tasks_dir(root) / task_id / "meta.json"
    if meta.exists():
        try:
            m = json.loads(meta.read_text(encoding="utf-8"))
            s = m.get("skill", "")
            if s:
                return s
        except Exception:
            return ""
    return ""


def skill_clarification_policy(root: Path, skill: str, smeta: Dict[str, Any]) -> str:
    p = str(smeta.get("clarification_policy", "")).strip().lower()
    if p in {"ask_user", "auto"}:
        return p
    meta, _ = parse_skill_yaml(skills_dir(root) / skill / "skill.yaml")
    p2 = str(meta.get("clarification_policy", "auto")).strip().lower()
    if p2 in {"ask_user", "auto"}:
        return p2
    return "auto"


def resolve_output_paths(root: Path, task_id: str, skill_meta: Dict[str, Any], skill: str) -> Tuple[str, str, str, str]:
    patch = "NONE"
    report = "NONE"
    result = "NONE"
    staged = ""
    outputs = skill_meta.get("outputs", []) or []
    for item in outputs:
        if "patch" in item:
            p = item["patch"].replace("<task_id>", task_id)
            path = root / p
            patch = p if path.exists() else "NONE"
        if "review" in item:
            p = item["review"].replace("<task_id>", task_id)
            if p.endswith("..."):
                rdir = root / p[:-3]
                if rdir.exists():
                    matches = sorted([x for x in rdir.glob("*.md")])
                    if matches:
                        report = str(matches[0].relative_to(root))
                continue
            path = root / p
            report = p if path.exists() else "NONE"

    if patch == "NONE":
        p = f"AGENTS/tasks/{task_id}/deliverable/patchset/patch.diff"
        if (root / p).exists():
            patch = p
    if report == "NONE":
        rdir = root / f"AGENTS/tasks/{task_id}/review"
        if rdir.exists():
            files = sorted(rdir.glob("*.md"))
            if files:
                report = str(files[0].relative_to(root))
    compute_result = f"AGENTS/tasks/{task_id}/outputs/compute/result.json"
    lit_candidates = f"AGENTS/tasks/{task_id}/outputs/lit/raw_candidates.jsonl"
    if (root / compute_result).exists():
        result = compute_result
    elif (root / lit_candidates).exists():
        result = lit_candidates
    stage_dir = f"GATE/staged/{task_id}/{skill}"
    if (root / stage_dir).exists():
        staged = stage_dir
    return patch, report, result, staged


def stderr_tail(text: str, max_lines: int = 8) -> str:
    lines = [x for x in text.splitlines() if x.strip()]
    if not lines:
        return ""
    return "\n".join(lines[-max_lines:])


def classify_error(err: Exception, phase: str, stderr_hint: str = "") -> Tuple[str, str]:
    if isinstance(err, NonInteractivePromptError):
        return "Non-interactive shell requires explicit approval mode.", "Run with --yes or --no."
    if isinstance(err, FileNotFoundError):
        return "Missing file or path.", "Input path is wrong or working directory is incorrect."
    if isinstance(err, JSONDecodeError):
        return "Malformed JSON content.", "A config/request file has invalid JSON syntax."
    if isinstance(err, PermissionError):
        return "Permission denied.", "File permissions or sandbox restrictions blocked access."
    if isinstance(err, SkillSubprocessError):
        tail = stderr_tail(stderr_hint or err.stderr)
        if "not found" in tail.lower() or "command not found" in tail.lower():
            return "Subprocess failed: required tool is missing.", "Install the missing binary and retry."
        return "Subprocess exited non-zero.", "Skill command failed; inspect stderr and skill logs."
    msg = str(err).lower()
    if "http" in msg or "url" in msg or "network" in msg or "rate limit" in msg or "unauthorized" in msg:
        return "Network/API request failed.", "Network issue, rate limit, or authentication problem."
    if "yaml" in msg and "parse" in msg:
        return "YAML parse failed.", "Malformed YAML in configuration/request."
    return "Unknown runtime failure.", "Unknown root cause."


def traceback_where(err: Exception) -> str:
    tb = traceback.extract_tb(err.__traceback__) if err.__traceback__ else []
    if not tb:
        return "unknown"
    top = tb[-3:]
    return " | ".join([f"{Path(f.filename).name}:{f.lineno} in {f.name}" for f in top])


def write_error_report(root: Path, task_id: str, phase: str, err: Exception, stderr_hint: str = "") -> str:
    review_dir = tasks_dir(root) / task_id / "review"
    review_dir.mkdir(parents=True, exist_ok=True)
    out = review_dir / "error.md"

    likely, guess_default = classify_error(err, phase, stderr_hint=stderr_hint)
    likely_cause = likely
    if isinstance(err, SkillSubprocessError):
        likely_cause = f"{likely_cause}\nstderr_tail:\n{stderr_tail(stderr_hint or err.stderr) or '(none)'}"
    if guess_default == "Unknown root cause.":
        unknown_guess = "HYPOTHESIS: check request.md and skill-specific logs for the first failing command."
    else:
        unknown_guess = "N/A"

    trace = "".join(traceback.format_exception(type(err), err, err.__traceback__))
    next_step = f"Inspect AGENTS/tasks/{task_id}/logs and AGENTS/tasks/{task_id}/request.md."
    if isinstance(err, NonInteractivePromptError):
        next_step = f"Re-run: ./bin/agenthub run --task {task_id} --yes"

    content = (
        "# Error Report\n\n"
        f"ERROR_CLASS: {err.__class__.__name__}\n\n"
        f"ERROR_MESSAGE: {str(err)}\n\n"
        f"WHERE: {traceback_where(err)}\n\n"
        f"PHASE: {phase}\n\n"
        f"LIKELY_CAUSE: {likely_cause}\n\n"
        f"IF_UNKNOWN_GUESS: {unknown_guess}\n\n"
        f"RECOVERY_STEP: {next_step}\n\n"
        "FULL_TRACEBACK:\n"
        "```text\n"
        f"{trace}"
        "```\n"
    )
    out.write_text(content, encoding="utf-8")
    return str(out.relative_to(root))


def parse_missing_from_error_report(root: Path, report_path: str) -> str:
    p = root / report_path
    if not p.exists():
        return ""
    try:
        text = p.read_text(encoding="utf-8", errors="ignore")
    except Exception:
        return ""
    m = re.search(r"^missing:\s*(.+)$", text, flags=re.M | re.I)
    if m:
        val = m.group(1).strip()
        if val in {"[]", '[""]', ""}:
            return ""
        return val
    m2 = re.search(r"^MISSING=([^\n]+)$", text, flags=re.M)
    if m2:
        return m2.group(1).strip()
    return ""


def parse_detail_lines_from_error_report(root: Path, report_path: str) -> List[str]:
    p = root / report_path
    if not p.exists():
        return []
    try:
        text = p.read_text(encoding="utf-8", errors="ignore")
    except Exception:
        return []
    details: List[str] = []
    for key in ["error_code", "completeness_rules", "online_lookup", "stop_reason"]:
        m = re.search(rf"^{key}:\s*(.+)$", text, flags=re.M | re.I)
        if m:
            details.append(f"{key}: {m.group(1).strip()}")
    m_next = re.search(r"^next_actions:\s*$([\s\S]+)", text, flags=re.M)
    if m_next:
        after = m_next.group(1).splitlines()
        for ln in after:
            s = ln.strip()
            if s.startswith("- "):
                details.append(f"next_action: {s[2:].strip()}")
                break
    return details[:6]


def stage_task_outputs(root: Path, task_id: str, skill: str, stage_enabled: bool) -> str:
    env = os.environ.copy()
    env["AGENTHUB_STAGE_APPROVAL"] = "yes" if stage_enabled else "no"
    cp = subprocess.run(
        [str(root / "AGENTS" / "runtime" / "stage_to_gate.sh"), str(root), task_id, skill],
        cwd=str(root),
        env=env,
        text=True,
        capture_output=True,
    )
    if cp.returncode != 0:
        msg = (cp.stderr or cp.stdout or "").strip() or "stage_to_gate failed"
        raise RuntimeError(f"STAGE_TO_GATE_FAILED: {msg}")
    stage_dir = root / "GATE" / "staged" / task_id / skill
    return str(stage_dir.relative_to(root)) if stage_dir.exists() else ""


def promotion_actions_for_stage(root: Path, task_id: str, skill: str) -> List[Tuple[Path, Path, str]]:
    staged = root / "GATE" / "staged" / task_id / skill
    if not staged.exists():
        return []
    actions: List[Tuple[Path, Path, str]] = []
    profile_json = staged / "paper_profile.json"
    if profile_json.exists():
        actions.append((profile_json, root / "USER" / "paper" / "meta" / "paper_profile.json", "file"))
    refs_bib = staged / "review" / "refs.bib"
    if refs_bib.exists():
        actions.append((refs_bib, root / "USER" / "paper" / "bib" / f"{task_id}.refs.bib", "file"))
    src_dir = staged / "deliverable" / "src"
    if src_dir.exists():
        actions.append((src_dir, root / "USER" / "src" / "compute" / task_id, "dir"))
    slides_dir = staged / "deliverable" / "slides"
    if slides_dir.exists():
        actions.append((slides_dir, root / "USER" / "presentations" / task_id, "dir"))
    return actions


def write_promotion_preview(root: Path, task_id: str, skill: str) -> Tuple[str, str]:
    staged_root = root / "GATE" / "staged" / task_id
    staged_skill = staged_root / skill
    preview = staged_root / "PROMOTE.md"
    next_cmd = f"./bin/agenthub promote --task {task_id}"

    actions = promotion_actions_for_stage(root, task_id, skill) if staged_skill.exists() else []
    lines = [
        "# Prepare To Promote",
        "",
        f"- task_id: {task_id}",
        f"- skill: {skill}",
        f"- staged_dir: GATE/staged/{task_id}/{skill}",
        "",
        "PROMOTION_STATUS=READY",
        f"PROMOTE_PREVIEW_PATH=GATE/staged/{task_id}/PROMOTE.md",
        "",
        "## File Mapping (GATE -> USER)",
    ]
    if actions:
        for src, dst, _ in actions:
            try:
                src_rel = str(src.relative_to(root))
            except Exception:
                src_rel = str(src)
            try:
                dst_rel = str(dst.relative_to(root))
            except Exception:
                dst_rel = str(dst)
            lines.append(f"- {src_rel} -> {dst_rel}")
    else:
        lines.append("- (no known mappings discovered for this skill)")
    lines += [
        "",
        'Warning: Promotion requires explicit user confirmation. The workflow is paused.',
        "",
    ]
    staged_root.mkdir(parents=True, exist_ok=True)
    preview.write_text("\n".join(lines), encoding="utf-8")
    return str(preview.relative_to(root)), next_cmd


def print_error_summary(root: Path, err: Exception, report_path: str) -> None:
    short = str(err).strip().splitlines()[0] if str(err).strip() else err.__class__.__name__
    if len(short) > 140:
        short = short[:137] + "..."
    if isinstance(err, SkillSubprocessError):
        short = f"{err.skill} exited non-zero (exit code {err.returncode})"
    print(f"ERROR={short}", file=sys.stderr)
    print(f"SEE={report_path}", file=sys.stderr)
    missing = parse_missing_from_error_report(root, report_path)
    if missing:
        print(f"MISSING={missing}", file=sys.stderr)
    print("EXIT=nonzero", file=sys.stderr)


def prompt_yes_no_fuzzy_tty(prompt: str) -> Tuple[bool, bool]:
    try:
        with open("/dev/tty", "r+", encoding="utf-8") as tty:
            tty.write(prompt)
            tty.flush()
            ans = tty.readline().strip().lower()
            if ans in {"yes", "y"}:
                return True, False
            if ans in {"no", "n", ""}:
                return False, False
            tty.write(prompt)
            tty.flush()
            ans2 = tty.readline().strip().lower()
            if ans2 in {"yes", "y"}:
                return True, False
            return False, False
    except Exception:
        try:
            ans = input(prompt).strip().lower()
        except EOFError:
            return False, True
        if ans in {"yes", "y"}:
            return True, False
        if ans in {"no", "n", ""}:
            return False, False
        try:
            ans2 = input(prompt).strip().lower()
        except EOFError:
            return False, True
        if ans2 in {"yes", "y"}:
            return True, False
        return False, False


def cmd_run(root: Path, args: argparse.Namespace) -> int:
    task_id = args.task
    phase = "run"
    try:
        idx = ensure_index(root)
        skill = args.skill or infer_skill(root, task_id)
        if not skill:
            raise RuntimeError("Missing skill. Provide --skill or set skill in AGENTS/tasks/<task_id>/meta.json")

        smeta = load_skill_from_index(idx, skill)
        if not smeta:
            meta, _ = parse_skill_yaml(skills_dir(root) / skill / "skill.yaml")
            smeta = {"name": skill, "run": meta.get("run", "scripts/run.sh")}
        run_rel = str(smeta.get("run", "scripts/run.sh")).strip()
        if run_rel != "scripts/run.sh":
            raise RuntimeError(f"SKILL_ENTRYPOINT_INVALID skill={skill} run={run_rel} required=scripts/run.sh")

        if args.yes and args.no:
            raise RuntimeError("Use only one of --yes or --no.")
        if args.stage_gate and args.no_stage_gate:
            raise RuntimeError("Use only one of --stage-gate or --no-stage-gate.")

        interactive_tty = sys.stdin.isatty()
        agent_mode_on = bool(args.agent_mode or env_truthy("AGENT_MODE", False))
        auto_promote_user = bool(args.auto_promote_user or env_truthy("AUTO_PROMOTE_USER", False))
        if not agent_mode_on:
            auto_promote_user = False

        if is_compute_skill(skill):
            preflight = request_preflight_status(root, task_id, skill)
            if not preflight["request_complete"]:
                request_step = str(preflight["request_step"])
                need_input_path = write_need_input_md(root, task_id, skill, request_step)
                print("RUN_STATUS=PAUSED_FOR_INPUT")
                print("REQUEST_COMPLETE=false")
                print(f"REQUEST_STEP={request_step}")
                print(f"NEED_INPUT_PATH={need_input_path}")
                print("STOP_REASON=need_user_input")
                print(schema_question_line(skill, request_step))
                print(f"MIN_EXAMPLE: {schema_example_line(request_step, skill)}")
                return 0
            if skill == "compute_algebraic_multistep":
                if args.execute and not review_ready_for_execute(root, task_id):
                    print("EXECUTION_ALLOWED=false")
                    print("STOP_REASON=need_user_review")
                    print("REVIEW_READY_FOR_EXECUTE=false")
                    print("HINT=Review required.")
                    return 0
                if not args.execute:
                    write_request_progress(root, task_id, str(preflight["request_step"]), review_ready_for_execute=False)

        # Run is non-interactive by design; approval_mode defaults to "no"
        # unless explicitly set to --yes.
        approval_mode = "yes" if args.yes else "no"

        phase = "skill_run"
        env = os.environ.copy()
        env["APPROVAL_MODE"] = approval_mode
        env["APPROVAL_INTERACTIVE"] = "1" if interactive_tty else "0"
        env["ALLOW_USER_WRITE"] = "1" if args.write_user else "0"
        env["SKILL_CLARIFICATION_POLICY"] = skill_clarification_policy(root, skill, smeta)
        env["ONLINE_LOOKUP"] = "1" if args.online else "0"
        env["NET_ALLOWED"] = "1" if args.net else "0"
        env["COMPUTE_EXECUTE"] = "1" if args.execute else "0"
        debug_mode = env_truthy("AGENTHUB_DEBUG", False)
        cp = subprocess.run(
            [str(root / "bin" / "agentctl"), "run", skill, "--task", task_id],
            cwd=str(root),
            env=env,
            text=True,
            capture_output=True,
        )
        if cp.returncode != 0:
            if cp.stdout.strip():
                safe_stdout = sanitize_user_lines(root, task_id, cp.stdout)
                if safe_stdout:
                    print(safe_stdout)
            raise SkillSubprocessError(skill=skill, returncode=cp.returncode, stdout=cp.stdout, stderr=cp.stderr)
        if cp.stdout.strip():
            safe_stdout = sanitize_user_lines(root, task_id, cp.stdout)
            if safe_stdout:
                if skill == "compute_algebraic_multistep" and not args.execute:
                    kept = []
                    for line in safe_stdout.splitlines():
                        if line.startswith("PLAN_STATUS=") or line.startswith("EXECUTION_ALLOWED="):
                            continue
                        kept.append(line)
                    if kept:
                        print("\n".join(kept).strip())
                else:
                    print(safe_stdout)
        if debug_mode and cp.stderr.strip():
            print(cp.stderr.strip(), file=sys.stderr)

        if skill == "compute_algebraic_multistep" and not args.execute:
            issue_review_token(root, task_id, current_step="done")
            plan_path = f"AGENTS/tasks/{task_id}/work/src/plan.json"
            report_plan_path = f"AGENTS/tasks/{task_id}/work/report_plan.md"
            print("PLAN_STATUS=READY_FOR_REVIEW")
            print("EXECUTION_ALLOWED=false")
            print("STOP_REASON=need_user_review")
            print(f"PLAN_PATH={plan_path if (root / plan_path).exists() else 'NONE'}")
            print(f"REPORT_PLAN_PATH={report_plan_path if (root / report_plan_path).exists() else 'NONE'}")
            print("Review required.")
            return 0

        phase = "stage"
        if args.no_stage_gate:
            print("NOTE=--no-stage-gate ignored; staging is mandatory on successful runs.")
        stage_enabled = True
        staged_dir = stage_task_outputs(root, task_id, skill, stage_enabled=stage_enabled)

        phase = "summary"
        patch, report, result, staged = resolve_output_paths(root, task_id, smeta, skill)
        if staged_dir:
            staged = staged_dir
        review_dir = f"AGENTS/tasks/{task_id}/review"

        print(f"TASK_ID: {task_id}")
        print(f"SKILL: {skill}")
        print(f"REVIEW_DIR_PATH: {review_dir if (root / review_dir).exists() else 'NONE'}")
        print(f"REPORT_PATH: {report}")
        print(f"OUTPUT_PATH: {result}")
        print(f"STAGED_DIR_PATH: {staged or 'NONE'}")
        print(f"AGENT_MODE={'on' if agent_mode_on else 'off'}")
        print(f"AUTO_PROMOTE_USER={'on' if auto_promote_user else 'off'}")

        phase = "promotion"
        preview_path, _next_cmd = write_promotion_preview(root, task_id, skill)
        print("PROMOTION_STATUS=READY")
        print(f"PROMOTE_PLAN_PATH: {preview_path}")
        print("PROMOTION_PENDING: true")
        print("Run completed. Inspect GATE output. I will promote only when you say READY.")
        return 0
    except Exception as err:
        skill_error = tasks_dir(root) / task_id / "review" / "error.md"
        if isinstance(err, SkillSubprocessError) and skill_error.exists():
            report = str(skill_error.relative_to(root))
        else:
            report = write_error_report(root, task_id, phase=phase, err=err, stderr_hint=getattr(err, "stderr", ""))
        print_error_summary(root, err, report)
        return 2


def cmd_promote(root: Path, args: argparse.Namespace) -> int:
    task_id = args.task
    staged_root = root / "GATE" / "staged" / task_id
    if not staged_root.exists():
        print(f"PROMOTE_TO_USER=blocked reason=missing_staged_task task={task_id}", file=sys.stderr)
        return 2

    interactive_tty = sys.stdin.isatty()
    if args.yes and args.no:
        print("ERROR=Use only one of --yes or --no.", file=sys.stderr)
        return 2
    if args.no:
        print("PROMOTE_TO_USER=skipped reason=user_declined")
        return 0

    confirmed_yes = bool(args.yes)
    if interactive_tty and not confirmed_yes:
        answer, interactive_error = prompt_yes_no_fuzzy_tty("PROMOTE_TO_USER? [y/N]")
        if interactive_error:
            print("PROMOTE_TO_USER=blocked reason=interactive_prompt_failed", file=sys.stderr)
            return 2
        if not answer:
            print("PROMOTE_TO_USER=skipped reason=user_declined")
            return 0
        confirmed_yes = True

    if not interactive_tty:
        if not (args.yes and args.allow_user_write_noninteractive):
            print("PROMOTE_TO_USER=skipped reason=noninteractive_requires_explicit_flags")
            return 0

    cmd = ["bash", "AGENTS/runtime/promote_to_user.sh", "--task", task_id]
    if confirmed_yes:
        cmd.append("--yes")
    if not interactive_tty and args.allow_user_write_noninteractive:
        cmd.append("--allow-user-write-noninteractive")
    cp = subprocess.run(cmd, cwd=str(root), text=True, capture_output=True)
    if cp.returncode != 0:
        msg = (cp.stderr or cp.stdout or "promotion failed").strip()
        print(f"PROMOTE_TO_USER=blocked reason={msg}", file=sys.stderr)
        return 2
    targets = []
    receipt = ""
    for line in cp.stdout.splitlines():
        t = line.strip()
        if t.startswith("PROMOTED_TARGET="):
            targets.append(t.split("=", 1)[1].strip())
        if t.startswith("PROMOTION_RECEIPT="):
            receipt = t.split("=", 1)[1].strip()
    target = targets[0] if targets else "unknown"
    print(f"PROMOTE_TO_USER=done target={target}")
    if receipt:
        print(f"PROMOTION_RECEIPT={receipt}")
    return 0


def prompt_yes_no(prompt: str) -> Tuple[bool, bool]:
    try:
        ans = input(prompt).strip().lower()
    except EOFError:
        return False, True
    return ans in {"y", "yes"}, False


def prompt_yes_no_fuzzy(prompt: str) -> Tuple[bool, bool]:
    try:
        ans = input(prompt).strip().lower()
    except EOFError:
        return False, True
    if ans in {"yes", "y"}:
        return True, False
    if ans in {"no", "n", ""}:
        return False, False
    # ambiguous: ask once more, then default NO
    try:
        ans2 = input(prompt).strip().lower()
    except EOFError:
        return False, True
    if ans2 in {"yes", "y"}:
        return True, False
    return False, False


def cmd_doctor(root: Path) -> int:
    errors: List[str] = []
    checks = [
        root / "AGENTS" / "skills",
        root / "AGENTS" / "tasks",
        root / "USER",
        root / "GATE",
        root / "bin" / "agentctl",
    ]
    for p in checks:
        if not p.exists():
            errors.append(f"missing:{p.relative_to(root)}")

    agentctl = root / "bin" / "agentctl"
    if agentctl.exists() and not os.access(agentctl, os.X_OK):
        errors.append("agentctl_not_executable")

    sdir = skills_dir(root)
    if sdir.exists():
        for s in sorted(sdir.iterdir()):
            if not s.is_dir():
                continue
            if not (s / "scripts" / "run.sh").exists():
                errors.append(f"missing_run_sh:{s.relative_to(root)}/scripts/run.sh")
            if (s / "run.sh").exists() or (s / "prompt.md").exists() or (s / "schema.json").exists():
                errors.append(f"root_duplicate_files:{s.relative_to(root)}")
            meta, warns = parse_skill_yaml(s / "skill.yaml")
            if str(meta.get("run", "")).strip() != "scripts/run.sh":
                errors.append(f"invalid_runner_path:{s.relative_to(root)}/skill.yaml")

    if errors:
        for e in errors:
            print(f"ERROR={e}")
        return 1

    print("DOCTOR=ok")
    return 0


def cmd_plan_revise(root: Path, args: argparse.Namespace) -> int:
    task_id = args.task
    feedback = str(args.feedback or "").strip()
    if not feedback:
        print("ERROR=--feedback is required.", file=sys.stderr)
        return 2
    skill = infer_skill(root, task_id)
    if skill != "compute_algebraic_multistep":
        print("ERROR=plan-revise is only supported for compute_algebraic_multistep.", file=sys.stderr)
        return 2
    preflight = request_preflight_status(root, task_id, skill)
    if not preflight["request_complete"]:
        request_step = str(preflight["request_step"])
        need_input_path = write_need_input_md(root, task_id, skill, request_step)
        print("RUN_STATUS=PAUSED_FOR_INPUT")
        print("REQUEST_COMPLETE=false")
        print(f"REQUEST_STEP={request_step}")
        print(f"NEED_INPUT_PATH={need_input_path}")
        print("STOP_REASON=need_user_input")
        print(schema_question_line(skill, request_step))
        print(f"MIN_EXAMPLE: {schema_example_line(request_step, skill)}")
        return 0

    tdir = tasks_dir(root) / task_id
    feedback_path = tdir / "work" / "src" / "plan_feedback.txt"
    feedback_path.parent.mkdir(parents=True, exist_ok=True)
    timestamp = now_utc()
    with feedback_path.open("a", encoding="utf-8") as handle:
        handle.write(f"[{timestamp}] {feedback}\n")

    env = os.environ.copy()
    env["APPROVAL_MODE"] = "no"
    env["APPROVAL_INTERACTIVE"] = "0"
    env["ALLOW_USER_WRITE"] = "0"
    env["SKILL_CLARIFICATION_POLICY"] = "auto"
    env["ONLINE_LOOKUP"] = "0"
    env["NET_ALLOWED"] = "0"
    env["COMPUTE_EXECUTE"] = "0"
    cp = subprocess.run(
        [str(root / "bin" / "agentctl"), "run", skill, "--task", task_id],
        cwd=str(root),
        env=env,
        text=True,
        capture_output=True,
    )
    if cp.returncode != 0:
        report = write_error_report(root, task_id, phase="plan_revise", err=SkillSubprocessError(skill, cp.returncode, cp.stdout, cp.stderr), stderr_hint=cp.stderr)
        print_error_summary(root, RuntimeError("plan revise failed"), report)
        return 2
    if cp.stdout.strip():
        safe_stdout = sanitize_user_lines(root, task_id, cp.stdout)
        if safe_stdout:
            kept = []
            for line in safe_stdout.splitlines():
                if line.startswith("PLAN_STATUS=") or line.startswith("EXECUTION_ALLOWED="):
                    continue
                kept.append(line)
            if kept:
                print("\n".join(kept).strip())
    write_request_progress(root, task_id, "done", review_ready_for_execute=False)
    issue_review_token(root, task_id, current_step="done")
    plan_path = f"AGENTS/tasks/{task_id}/work/src/plan.json"
    report_plan_path = f"AGENTS/tasks/{task_id}/work/report_plan.md"
    print("PLAN_STATUS=READY_FOR_REVIEW")
    print("EXECUTION_ALLOWED=false")
    print("STOP_REASON=need_user_review")
    print(f"PLAN_PATH={plan_path if (root / plan_path).exists() else 'NONE'}")
    print(f"REPORT_PLAN_PATH={report_plan_path if (root / report_plan_path).exists() else 'NONE'}")
    print(f"PLAN_FEEDBACK_PATH={feedback_path.relative_to(root)}")
    print("Review required.")
    return 0


def cmd_review_accept(root: Path, args: argparse.Namespace) -> int:
    task_id = args.task
    provided_token = str(args.token or "").strip()
    meta_path = tasks_dir(root) / task_id / "meta.json"
    if not meta_path.exists():
        print(f"ERROR=Task not found: {task_id}", file=sys.stderr)
        return 2
    try:
        meta = json.loads(meta_path.read_text(encoding="utf-8"))
    except Exception:
        print(f"ERROR=Invalid task metadata: {task_id}", file=sys.stderr)
        return 2
    skill = str(meta.get("skill", "")).strip()
    if skill != "compute_algebraic_multistep":
        print("ERROR=review-accept is only supported for compute_algebraic_multistep.", file=sys.stderr)
        return 2
    token_file = review_token_path(root, task_id)
    if not provided_token or not token_file.exists():
        print("REVIEW_ACCEPTED=false")
        print("REVIEW_READY_FOR_EXECUTE=false")
        print("STOP_REASON=need_user_review")
        return 2
    expected_token = token_file.read_text(encoding="utf-8").strip()
    if not expected_token or not hmac.compare_digest(provided_token, expected_token):
        print("REVIEW_ACCEPTED=false")
        print("REVIEW_READY_FOR_EXECUTE=false")
        print("STOP_REASON=need_user_review")
        return 2
    progress = load_request_progress(root, task_id)
    current_step = str(progress.get("current_step", "")).strip() or "done"
    write_request_progress(root, task_id, current_step, review_ready_for_execute=True)
    print("REVIEW_ACCEPTED=true")
    print("REVIEW_READY_FOR_EXECUTE=true")
    print("STOP_REASON=request_complete_waiting_user_execute")
    return 0


def main() -> int:
    root = repo_root()

    parser = argparse.ArgumentParser(prog="agenthub")
    sub = parser.add_subparsers(dest="cmd", required=True)

    sub.add_parser("index")

    ps = sub.add_parser("suggest")
    ps.add_argument("text")

    pstart = sub.add_parser("start")
    pstart.add_argument("--skill", required=True)
    pstart.add_argument("--task-name", default=None)
    pstart.add_argument("--request", default=None)
    pstart.add_argument("--request-file", default=None)
    pstart.add_argument("--edit", action="store_true")

    prun = sub.add_parser("run")
    prun.add_argument("--task", required=True)
    prun.add_argument("--skill", default=None)
    prun.add_argument("--yes", action="store_true")
    prun.add_argument("--no", action="store_true")
    prun.add_argument("--write-user", action="store_true")
    prun.add_argument("--online", action="store_true")
    prun.add_argument("--net", action="store_true")
    prun.add_argument("--stage-gate", action="store_true")
    prun.add_argument("--no-stage-gate", action="store_true")
    prun.add_argument("--agent-mode", action="store_true")
    prun.add_argument("--auto-promote-user", action="store_true")
    prun.add_argument("--allow-user-write-noninteractive", action="store_true")
    prun.add_argument("--execute", action="store_true")

    ppromote = sub.add_parser("promote")
    ppromote.add_argument("--task", required=True)
    ppromote.add_argument("--yes", action="store_true")
    ppromote.add_argument("--no", action="store_true")
    ppromote.add_argument("--allow-user-write-noninteractive", action="store_true")

    pname = sub.add_parser("task-name")
    pname.add_argument("--skill", required=True)

    preq = sub.add_parser("request-set")
    preq.add_argument("--task", required=True)
    preq.add_argument("--field", required=True)
    preq.add_argument("--value", default=None)
    preq.add_argument("--file", default=None)

    prevacc = sub.add_parser("review-accept")
    prevacc.add_argument("--task", required=True)
    prevacc.add_argument("--token", required=True)

    sub.add_parser("doctor")

    previse = sub.add_parser("plan-revise")
    previse.add_argument("--task", required=True)
    previse.add_argument("--feedback", required=True)

    args = parser.parse_args()

    if args.cmd == "index":
        return cmd_index(root)
    if args.cmd == "suggest":
        return cmd_suggest(root, args.text)
    if args.cmd == "start":
        return cmd_start(root, args)
    if args.cmd == "run":
        return cmd_run(root, args)
    if args.cmd == "promote":
        return cmd_promote(root, args)
    if args.cmd == "task-name":
        print(f"TASK_NAME={default_task_name(args.skill)}")
        return 0
    if args.cmd == "request-set":
        return cmd_request_set(root, args)
    if args.cmd == "review-accept":
        return cmd_review_accept(root, args)
    if args.cmd == "doctor":
        return cmd_doctor(root)
    if args.cmd == "plan-revise":
        return cmd_plan_revise(root, args)

    return 2


if __name__ == "__main__":
    raise SystemExit(main())
